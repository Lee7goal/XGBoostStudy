{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n其中，1{.}是示性函数，当{}中的表达式为真时取值为1，否则为0，\\n如1{1+2=3}=1，1{3-1=3}=0。由前述内容可知，\\nsoftmax回归是逻辑回归的扩展与推广，因此逻辑回归的损失函数也可改写为上述形式，\\n如下：[插图]\\n得到softmax回归的损失函数之后，可以通过梯度下降法对其进行参数估计。J（ω）对参数求偏导后得到梯度公式，如下：\\n[插图]\\n将其代入梯度下降算法用以更新相关参数，多步迭代后最终得到最优参数。\\n由前述内容可知，逻辑回归可以很好地解决二分类的问题，其实经过适当运用，也可用于解决多分类问题。\\n对于多分类问题，为每个类别分别建一个二分类器，如果样本属于该类别，则label标记为1，否则标记为0。\\n假如有k个类别，最后就会得到k个针对不同分类的二分类器。对于新的样本，\\n通过这k个二分类器进行预测，每个分类器即可判断该样本是否属于该分类。通过softmax回归和多个二分类器都可以解决多分类问题，\\n那什么时候使用softmax回归，什么时候应该使用多个二分类器？\\n这取决于多分类问题中，类别之间是否互斥，即样本能否同时属于多个类别。\\n如果类别之间是互斥的，样本不可能同时属于多个类别，则选择softmax回归；如果类别之间不是互斥的，则选择多个二分类器更为合适。\\n'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 1
    }
   ],
   "source": [
    "\"\"\"\n",
    "3.3.4 softmax前面介绍了逻辑回归模型，它可以很好地解决二分类问题。那么多分类问题该如何处理呢？\n",
    "这就需要用到softmax回归模型。可以将softmax回归模型理解为逻辑回归模型在多分类问题上的推广，\n",
    "不同的是分类标签由2个变成了多个。最有名的多分类问题是MNIST数字标识任务，该数据集是通过手写体识别10个不同的数字，\n",
    "即有10个不同的分类标签。首先来看softmax的函数形式。\n",
    "假设给定输入x，函数给定每一个类别j的预测概率为P（y=j|x），\n",
    "总共有k个类别，则softmax函数为：[插图]即[插图]softmax将值的范围限制在0～1之间，\n",
    "其中[插图]是对概率分布进行归一化，使得所有概率之和为1。细心的读者肯定会发现，\n",
    "softmax函数和sigmoid函数有一些相似，其实softmax就是sigmoid函数的扩展。\n",
    "当类别数k为2时，softmax回归退化为逻辑回归。\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "softmax将值的范围限制在0～1之间，其中[插图]是对概率分布进行归一化，使得所有概率之和为1。\n",
    "细心的读者肯定会发现，softmax函数和sigmoid函数有一些相似，其实softmax就是sigmoid函数的扩展。\n",
    "当类别数k为2时，softmax回归退化为逻辑回归。\n",
    "了解了softmax的定义之后，下面来看一下softmax的损失函数，定义如下：\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "其中，1{.}是示性函数，当{}中的表达式为真时取值为1，否则为0，\n",
    "如1{1+2=3}=1，1{3-1=3}=0。由前述内容可知，\n",
    "softmax回归是逻辑回归的扩展与推广，因此逻辑回归的损失函数也可改写为上述形式，\n",
    "如下：[插图]\n",
    "得到softmax回归的损失函数之后，可以通过梯度下降法对其进行参数估计。J（ω）对参数求偏导后得到梯度公式，如下：\n",
    "[插图]\n",
    "将其代入梯度下降算法用以更新相关参数，多步迭代后最终得到最优参数。\n",
    "由前述内容可知，逻辑回归可以很好地解决二分类的问题，其实经过适当运用，也可用于解决多分类问题。\n",
    "对于多分类问题，为每个类别分别建一个二分类器，如果样本属于该类别，则label标记为1，否则标记为0。\n",
    "假如有k个类别，最后就会得到k个针对不同分类的二分类器。对于新的样本，\n",
    "通过这k个二分类器进行预测，每个分类器即可判断该样本是否属于该分类。通过softmax回归和多个二分类器都可以解决多分类问题，\n",
    "那什么时候使用softmax回归，什么时候应该使用多个二分类器？\n",
    "这取决于多分类问题中，类别之间是否互斥，即样本能否同时属于多个类别。\n",
    "如果类别之间是互斥的，样本不可能同时属于多个类别，则选择softmax回归；如果类别之间不是互斥的，则选择多个二分类器更为合适。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}